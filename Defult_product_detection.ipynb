{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1ddc23d",
      "metadata": {
        "id": "f1ddc23d"
      },
      "outputs": [],
      "source": [
        "import numpy as np #importing the numpy module which we will be using in this project\n",
        "import pandas as pd #importing the pandas module which will be used in this porject\n",
        "import string#importing the pandas module which will be used in this porject\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV#importing the test_train_split module which will be used in this porject\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score #importing the classification report adn the confusion matrix module which will be used in this porject\n",
        "import nltk#importing the nltk module which will be used in this porject\n",
        "from nltk.corpus import stopwords#importing the nltk.corpus.stopwords module which will be used in this porject\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer#importing the extraction.text.CountVectorizer and TfidfTransformer module which will be used in this porject\n",
        "from sklearn.pipeline import Pipeline#importing the sklearn.pipeline.Pipeline module which will be used in this porject\n",
        "from sklearn.ensemble import RandomForestClassifier#importing the sklearn.ensemble.RandomForestClassifier module which will be used in this porject\n",
        "from sklearn.svm import SVC#importing the sklearn.svm.SVC module which will be used in this porject\n",
        "from sklearn.linear_model import LogisticRegression#importing the sklearn.linear_model.LogisticRegression module which will be used in this porject"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46e09e82",
      "metadata": {
        "scrolled": true,
        "id": "46e09e82",
        "outputId": "139d1148-42b6-4710-cdfc-df2482552ac4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>category</th>\n",
              "      <th>rating</th>\n",
              "      <th>label</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Home_and_Kitchen_5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>CG</td>\n",
              "      <td>love well made sturdi comfort i love veri pretti</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Home_and_Kitchen_5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>CG</td>\n",
              "      <td>love great upgrad origin i 've mine coupl year</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Home_and_Kitchen_5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>CG</td>\n",
              "      <td>thi pillow save back i love look feel pillow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Home_and_Kitchen_5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>CG</td>\n",
              "      <td>miss inform use great product price i</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Home_and_Kitchen_5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>CG</td>\n",
              "      <td>veri nice set good qualiti we set two month</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0            category  rating label  \\\n",
              "0           0  Home_and_Kitchen_5     5.0    CG   \n",
              "1           1  Home_and_Kitchen_5     5.0    CG   \n",
              "2           2  Home_and_Kitchen_5     5.0    CG   \n",
              "3           3  Home_and_Kitchen_5     1.0    CG   \n",
              "4           4  Home_and_Kitchen_5     5.0    CG   \n",
              "\n",
              "                                              text_  \n",
              "0  love well made sturdi comfort i love veri pretti  \n",
              "1    love great upgrad origin i 've mine coupl year  \n",
              "2      thi pillow save back i love look feel pillow  \n",
              "3             miss inform use great product price i  \n",
              "4       veri nice set good qualiti we set two month  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframe = pd.read_csv('datasest.csv') #reading our dataset which contains text and a label whether it is fake or real\n",
        "dataframe.head() #printing the first 5 columsn in our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec807090",
      "metadata": {
        "id": "ec807090"
      },
      "outputs": [],
      "source": [
        "dataframe.drop('Unnamed: 0',axis=1,inplace=True)## dropping the unnecessary column 'UNAMED'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "210251cc",
      "metadata": {
        "scrolled": true,
        "id": "210251cc",
        "outputId": "588b7dc2-5d35-4b14-8dbf-f303ebf5cf0f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>rating</th>\n",
              "      <th>label</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Home_and_Kitchen_5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>CG</td>\n",
              "      <td>love well made sturdi comfort i love veri pretti</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Home_and_Kitchen_5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>CG</td>\n",
              "      <td>love great upgrad origin i 've mine coupl year</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Home_and_Kitchen_5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>CG</td>\n",
              "      <td>thi pillow save back i love look feel pillow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Home_and_Kitchen_5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>CG</td>\n",
              "      <td>miss inform use great product price i</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Home_and_Kitchen_5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>CG</td>\n",
              "      <td>veri nice set good qualiti we set two month</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             category  rating label  \\\n",
              "0  Home_and_Kitchen_5     5.0    CG   \n",
              "1  Home_and_Kitchen_5     5.0    CG   \n",
              "2  Home_and_Kitchen_5     5.0    CG   \n",
              "3  Home_and_Kitchen_5     1.0    CG   \n",
              "4  Home_and_Kitchen_5     5.0    CG   \n",
              "\n",
              "                                              text_  \n",
              "0  love well made sturdi comfort i love veri pretti  \n",
              "1    love great upgrad origin i 've mine coupl year  \n",
              "2      thi pillow save back i love look feel pillow  \n",
              "3             miss inform use great product price i  \n",
              "4       veri nice set good qualiti we set two month  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframe.head() #pritning the dataset again after dropping the column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5763dfc",
      "metadata": {
        "id": "a5763dfc"
      },
      "outputs": [],
      "source": [
        "dataframe.dropna(inplace=True) #dropping alll the null rows in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "304aa467",
      "metadata": {
        "id": "304aa467"
      },
      "outputs": [],
      "source": [
        "dataframe['length'] = dataframe['text_'].apply(len) #storing the length of all the text into a separate column called 'length'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "092b8ad0",
      "metadata": {
        "id": "092b8ad0"
      },
      "source": [
        "Let's extract the largest review..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e20b02e",
      "metadata": {
        "scrolled": true,
        "id": "7e20b02e",
        "outputId": "56571eae-a6d5-46bf-a7b1-1a05148508a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"weak on current scienc after see twice i agre much posit five star review out respect read review i 'll repeat everyth i like present i found goofi over ear hairdo facial hair arrang daniel vitali describ `` wild food expert '' distract ugh ditto david wolf extrem goofi wild hairdo on hand jon gabriel describ `` author weight loss expert '' nice groom good present hi stori person transform fellow pound whew becom jock normal weight inspir christian northrup preserv rank one america 's cutest doctor a realli nice look woman present dr. mercola jason vale kri carr alejandro junger fine it disappoint jami oliv popular uk give babi cow growth fluid pas unscientif popular idea milk none present anyth zilch say work doctor t. colin campbel milk bodi bad it good see present take stand sugar they agre evil sugar refin carbohydr with respect dr. northrup `` it 's fat make fat 's sugar '' statement pas muster commun expert recogn evil sugar not mutual exclus recogn proven danger fat particularli fat dead anim extract fat all kind oliv oil not health food data-hook= '' product-link-link '' class= '' a-link-norm '' href= '' /the-china-study-the-most-comprehensive-study-of-nutrition-ever-conducted-and-the-startling-implications-for-diet-weight-loss-and-long-term-health/dp/1932100660/ref=cm_cr_arp_d_rvw_txt ie=utf8 '' the china studi the most comprehens studi nutrit ever conduct and startl implic diet weight loss and long-term health /a data-hook= '' product-link-link '' class= '' a-link-norm '' href= '' /forks-over-knives/dp/b0053zhzi2/ref=cm_cr_arp_d_rvw_txt ie=utf8 '' fork over knive /a data-hook= '' product-link-link '' class= '' a-link-norm '' href= '' /prevent-and-reverse-heart-disease-the-revolutionary-scientifically-proven-nutrition-based-cure/dp/1583333002/ref=cm_cr_arp_d_rvw_txt ie=utf8 '' prevent revers heart diseas the revolutionari scientif proven nutrition-bas cure /a data-hook= '' product-link-link '' class= '' a-link-norm '' href= '' /the-plant-based-journey-a-step-by-step-guide-for-transitioning-to-a-healthy-lifestyle-and-achieving-your-ideal-weight/dp/1941631363/ref=cm_cr_arp_d_rvw_txt ie=utf8 '' the plant-bas journey a step-by-step guid transit healthi lifestyl achiev your ideal weight /a\""
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframe[dataframe['label']=='OR'][['text_','length']].sort_values(by='length',ascending=False).head().iloc[0].text_ ##so here we are just collecting the words which are most common in the fake reviews so that we can identify these wrods to detect for future text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81649454",
      "metadata": {
        "id": "81649454"
      },
      "outputs": [],
      "source": [
        "def convertmyTxt(rv): #here we are defining a function\n",
        "    np = [c for c in rv if c not in string.punctuation] #this function is checking if it is present in punctuation or not.\n",
        "    np = ''.join(np) #the character which are not in punctuation, we are storing them in a separate string\n",
        "    return [w for w in np.split() if w.lower() not in stopwords.words('english')] #here we are returning a list of words from the sentences we just made in above line and checking if it is not a stopword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "501767f8",
      "metadata": {
        "id": "501767f8"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(dataframe['text_'],dataframe['label'],test_size=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce7083df",
      "metadata": {
        "id": "ce7083df"
      },
      "outputs": [],
      "source": [
        "pip = Pipeline([\n",
        "    ('bow',CountVectorizer(analyzer=convertmyTxt)),\n",
        "    ('tfidf',TfidfTransformer()),\n",
        "    ('classifier',RandomForestClassifier())\n",
        "]) #here we are defining our Random Forest Classifier model in which we will pass the training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e5aad6e",
      "metadata": {
        "scrolled": true,
        "id": "7e5aad6e"
      },
      "outputs": [],
      "source": [
        "pip.fit(x_train,y_train) #here we are passing the testing and training data into Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ab07e65",
      "metadata": {
        "id": "0ab07e65",
        "outputId": "e9e58a8f-cd8c-48a8-f1a5-88d663002de1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['CG', 'CG', 'CG', ..., 'CG', 'CG', 'OR'], dtype=object)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "randomForestClassifier = pip.predict(x_test) #here we are predicting the accuracy of the Random Forest Classifier model\n",
        "randomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68e19966",
      "metadata": {
        "id": "68e19966",
        "outputId": "76d09105-8400-4b0c-de61-cdb0bfa468d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "          CG       0.80      0.89      0.84      7032\n",
            "          OR       0.88      0.78      0.83      7119\n",
            "\n",
            "    accuracy                           0.84     14151\n",
            "   macro avg       0.84      0.84      0.84     14151\n",
            "weighted avg       0.84      0.84      0.84     14151\n",
            "\n",
            "Confusion Matrix: [[6244  788]\n",
            " [1539 5580]]\n",
            "Accuracy Score: 0.835559324429369\n",
            "Model Prediction Accuracy: 83.56%\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy of the model: ',str(np.round(accuracy_score(y_test,randomForestClassifier)*100,2)) + '%')#here we are predicting the accuracy of the Random Forest Classifier model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "411b3693",
      "metadata": {
        "id": "411b3693"
      },
      "outputs": [],
      "source": [
        "pip = Pipeline([\n",
        "    ('bow',CountVectorizer(analyzer=convertmyTxt)),\n",
        "    ('tfidf',TfidfTransformer()),\n",
        "    ('classifier',SVC())\n",
        "])#here we are defining our Support Vector Classifier model in which we will pass the training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d166fa0b",
      "metadata": {
        "id": "d166fa0b",
        "outputId": "33fdd209-0d02-4153-cdc1-6b4c8700ff8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('bow',\n",
              "                 CountVectorizer(analyzer=<function text_process at 0x0000021F7471D940>)),\n",
              "                ('tfidf', TfidfTransformer()), ('classifier', SVC())])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pip.fit(x_train,y_train)#here we are passing the testing and training data into Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b1224c9",
      "metadata": {
        "id": "6b1224c9",
        "outputId": "42102e11-290a-483f-cecc-43daed42b4b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['CG', 'CG', 'CG', ..., 'OR', 'OR', 'OR'], dtype=object)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "supportVectorClassifier = pip.predict(x_test)#here we are predicting the accuracy of the Random Forest Classifier model\n",
        "supportVectorClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb5086a5",
      "metadata": {
        "id": "fb5086a5",
        "outputId": "2a702b32-24d9-4dd7-f191-394d36fe7d11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "          CG       0.89      0.87      0.88      7032\n",
            "          OR       0.87      0.89      0.88      7119\n",
            "\n",
            "    accuracy                           0.88     14151\n",
            "   macro avg       0.88      0.88      0.88     14151\n",
            "weighted avg       0.88      0.88      0.88     14151\n",
            "\n",
            "Confusion Matrix: [[6101  931]\n",
            " [ 752 6367]]\n",
            "Accuracy Score: 0.8810684757260971\n",
            "Model Prediction Accuracy: 88.11%\n"
          ]
        }
      ],
      "source": [
        "print('accuracy of the model:',str(np.round(accuracy_score(y_test,supportVectorClassifier)*100,2)) + '%')#here we are predicting the accuracy of the Random Forest Classifier model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe899074",
      "metadata": {
        "id": "fe899074"
      },
      "outputs": [],
      "source": [
        "pip = Pipeline([\n",
        "    ('bow',CountVectorizer(analyzer=text_process)),\n",
        "    ('tfidf',TfidfTransformer()),\n",
        "    ('classifier',LogisticRegression())\n",
        "])#here we are defining our Logistic Regression model in which we will pass the training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0daa08e",
      "metadata": {
        "id": "c0daa08e",
        "outputId": "956852c2-4964-40ec-c396-3d93070a52a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('bow',\n",
              "                 CountVectorizer(analyzer=<function text_process at 0x0000021F7471D940>)),\n",
              "                ('tfidf', TfidfTransformer()),\n",
              "                ('classifier', LogisticRegression())])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pip.fit(x_train,y_train)#here we are passing the testing and training data into Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "087b741a",
      "metadata": {
        "id": "087b741a",
        "outputId": "27438cc0-1c95-4305-ae2f-15766f3dd591"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['CG', 'CG', 'CG', ..., 'OR', 'OR', 'OR'], dtype=object)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logisticRegression = pip.predict(x_test)#here we are predicting the accuracy of the Random Forest Classifier model\n",
        "logisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a992daa6",
      "metadata": {
        "id": "a992daa6",
        "outputId": "4188b3d7-86d5-4506-ecf3-c2418f3b03b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "          CG       0.86      0.85      0.86      7032\n",
            "          OR       0.86      0.87      0.86      7119\n",
            "\n",
            "    accuracy                           0.86     14151\n",
            "   macro avg       0.86      0.86      0.86     14151\n",
            "weighted avg       0.86      0.86      0.86     14151\n",
            "\n",
            "Confusion Matrix: [[5996 1036]\n",
            " [ 938 6181]]\n",
            "Accuracy Score: 0.8605045579817681\n",
            "Model Prediction Accuracy: 86.05%\n"
          ]
        }
      ],
      "source": [
        "print('accuracy of the model:',str(np.round(accuracy_score(y_test,logisticRegression)*100,2)) + '%')#here we are predicting the accuracy of the Random Forest Classifier model"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}